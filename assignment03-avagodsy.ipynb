{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64952753",
   "metadata": {},
   "source": [
    "---\n",
    "title: Assignment 03\n",
    "author:\n",
    "    - name: Ava Godsy\n",
    "      affiliations:\n",
    "        - id: bu\n",
    "          name: Boston University\n",
    "          city: Boston\n",
    "          state: MA\n",
    "number-sections: true\n",
    "date: '2025-09-22'\n",
    "format:\n",
    "    html:\n",
    "        toc: true\n",
    "        toc-depth: 2\n",
    "        theme: cosmo\n",
    "    docx: default\n",
    "    pdf: default\n",
    "date-modified: today\n",
    "date-format: long\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a28377",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b067df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/23 02:37:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/23 02:38:07 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "#| eval: true\n",
    "#| echo: true\n",
    "#| fig-align: center\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
    "\n",
    "# Load Data\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"lightcast_job_postings.csv\")\n",
    "df.createOrReplaceTempView(\"job_postings\")\n",
    "\n",
    "# Show Schema and Sample Data\n",
    "# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
    "\n",
    "# df.printSchema() # comment this line when rendering the submission\n",
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bc1be",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf0f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medians: 87295.0 - 130042.0 - 115024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(\"float\")) \\\n",
    "       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n",
    "       .withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\")) \\\n",
    "       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\")) \\\n",
    "       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\"))\n",
    "\n",
    "def compute_median(sdf, col_name):\n",
    "    q = sdf.approxQuantile(col_name, [0.5], 0.01)\n",
    "    return q[0] if q else None\n",
    "\n",
    "median_from = compute_median(df, \"SALARY_FROM\")\n",
    "median_to = compute_median(df, \"SALARY_TO\")\n",
    "median_salary = compute_median(df, \"SALARY\")\n",
    "\n",
    "print(\"Medians:\", median_from, \"-\", median_to, \"-\", median_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701bf629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data cleaning complete. Rows retained: 72498\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna({\n",
    "    \"SALARY_FROM\": median_from,\n",
    "    \"SALARY_TO\": median_to\n",
    "})\n",
    "\n",
    "df = df.withColumn(\"Average_Salary\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n",
    "\n",
    "export_cols = [\n",
    "    \"EDUCATION_LEVELS_NAME\",\n",
    "    \"REMOTE_TYPE_NAME\",\n",
    "    \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"Average_Salary\",\n",
    "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"\n",
    "]\n",
    "df_selected = df.select (*export_cols)\n",
    "\n",
    "pdf = df_selected.toPandas()\n",
    "pdf.to_csv(\"lightcast_cleaned.csv\", index=False)\n",
    "\n",
    "print(\" Data cleaning complete. Rows retained:\", len(pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa513853",
   "metadata": {},
   "source": [
    "## video: 56 min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ff0c6",
   "metadata": {},
   "source": [
    "# Salary Distribution by Industry and Employment Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd15773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125f848a",
   "metadata": {},
   "source": [
    "# Salary Analysis by ONET Occupation Type (Bubble Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b88d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43529ae8",
   "metadata": {},
   "source": [
    "# Salary by Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292827d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ade6a0e1",
   "metadata": {},
   "source": [
    "# Salary by Remote Work Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949acb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
