{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7155b3e",
   "metadata": {},
   "source": [
    "---\n",
    "title: Assignment 03 AI Prompts\n",
    "author:\n",
    "    - name: Ava Godsy\n",
    "      affiliations:\n",
    "        - id: bu\n",
    "          name: Boston University\n",
    "          city: Boston\n",
    "          state: MA\n",
    "number-sections: true\n",
    "date: '2025-09-22'\n",
    "format:\n",
    "    html:\n",
    "        toc: true\n",
    "        toc-depth: 2\n",
    "        theme: cosmo\n",
    "    docx: default\n",
    "    pdf: default\n",
    "date-modified: today\n",
    "date-format: long\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10063b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cb1d06a",
   "metadata": {},
   "source": [
    "# Cleaning Education column\n",
    "\n",
    "## Prompt\n",
    "using python remove \"/n\" from values in column EDUCATION_LEVELS_NAME in dataframe \"df\"\n",
    "\n",
    "## Response\n",
    "To remove \"\\n\" (newline characters) from the values in the column EDUCATION_LEVELS_NAME in a DataFrame df, you can use the .str.replace() method from pandas.\n",
    "\n",
    "Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "df['EDUCATION_LEVELS_NAME'] = df['EDUCATION_LEVELS_NAME'].str.replace('\\n', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca6e37d",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "str.replace('\\n', '', regex=False) replaces all newline characters (\\n) with an empty string (''), effectively removing them.\n",
    "\n",
    "regex=False ensures that \\n is treated as a literal string (which is fine in this case since \\n is a special character anyway).\n",
    "\n",
    "If you also want to remove any leading or trailing spaces (common after removing \\n), you can chain .str.strip():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "df['EDUCATION_LEVELS_NAME'] = df['EDUCATION_LEVELS_NAME'].str.replace('\\n', '', regex=False).str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc00224",
   "metadata": {},
   "source": [
    "## Additional Prompt\n",
    "i got an error TypeError: 'Column' object is not callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c28b7",
   "metadata": {},
   "source": [
    "## Additional Response\n",
    "Thanks — the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b90476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "TypeError: 'Column' object is not callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28af7f",
   "metadata": {},
   "source": [
    "means you're likely using PySpark rather than pandas. In PySpark, DataFrame columns are represented by Column objects, and they behave differently than pandas Series.\n",
    "\n",
    "✅ Fix for PySpark\n",
    "\n",
    "If you're using PySpark and want to remove \\n from a column (like EDUCATION_LEVELS_NAME), use withColumn() and regexp_replace() from pyspark.sql.functions.\n",
    "\n",
    "Here's the correct code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c841bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df = df.withColumn(\"EDUCATION_LEVELS_NAME\", regexp_replace(\"EDUCATION_LEVELS_NAME\", \"\\n\", \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4bfe5",
   "metadata": {},
   "source": [
    "# Salary Distribution by Industry and Employment Type\n",
    "\n",
    "## Prompt\n",
    "Using Plotly, Create a box plot where: X-axis = NAICS2_NAME Y-axis = SALARY_FROM Group by EMPLOYMENT_TYPE_NAME. dataframe = data_selected\n",
    "\n",
    "## Response\n",
    "Here's how you can create a box plot using Plotly in Python, with:\n",
    "\n",
    "X-axis = NAICS2_NAME\n",
    "\n",
    "Y-axis = SALARY_FROM\n",
    "\n",
    "Grouped by = EMPLOYMENT_TYPE_NAME\n",
    "\n",
    "Dataframe = data_selected\n",
    "\n",
    "✅ Code using Plotly Express:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cc205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(\n",
    "    data_selected,\n",
    "    x=\"NAICS2_NAME\",\n",
    "    y=\"SALARY_FROM\",\n",
    "    color=\"EMPLOYMENT_TYPE_NAME\",\n",
    "    title=\"Salary Distribution by Industry and Employment Type\",\n",
    "    points=\"all\",  # Optional: shows all data points\n",
    "    notched=True   # Optional: adds notches to box for median CI\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Industry (NAICS2)\",\n",
    "    yaxis_title=\"Starting Salary\",\n",
    "    boxmode=\"group\",  # Groups boxes side by side\n",
    "    xaxis_tickangle=45  # Rotate x-axis labels for better readability\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2bbaf",
   "metadata": {},
   "source": [
    "## Additional Prompt\n",
    "make the height taller, change the colors to purple, blue and green. make the font garamond\n",
    "\n",
    "## Additional Response\n",
    "You can customize the height and colors of your Plotly box plot using the height parameter and the color_discrete_sequence argument.\n",
    "\n",
    "Here's the updated code with:\n",
    "\n",
    "Increased height\n",
    "\n",
    "Custom colors: purple, blue, green\n",
    "\n",
    "To set the font to Garamond in your Plotly chart, you can specify it in the update_layout() method using the font parameter.\n",
    "\n",
    "✅ Final Updated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56784a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(\n",
    "    df_selected,\n",
    "    x=\"NAICS2_NAME\",\n",
    "    y=\"SALARY_FROM\",\n",
    "    color=\"EMPLOYMENT_TYPE_NAME\",\n",
    "    title=\"Salary Distribution by Industry and Employment Type\",\n",
    "    points=\"all\",  # Show all points\n",
    "    notched=True,  # Notched boxes\n",
    "    height=700,  # Taller figure\n",
    "    color_discrete_sequence=[\"purple\", \"blue\", \"green\"]  # Custom colors\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Industry (NAICS2)\",\n",
    "    yaxis_title=\"Starting Salary\",\n",
    "    boxmode=\"group\",  # Grouped box plots\n",
    "    xaxis_tickangle=45,  # Rotate x-axis labels\n",
    "    font=dict(\n",
    "        family=\"Garamond, serif\",  # Set font to Garamond\n",
    "        size=14  # Optional: adjust font size\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062575a",
   "metadata": {},
   "source": [
    "# Salary Analysis by ONET Occupation Type Table\n",
    "## Prompt\n",
    "Using Python, create a table of median \"SALARY\" by ONET_NAME. also include a count of records for each ONET_NAME, call the column Job_Postings\n",
    "\n",
    "## Response\n",
    "To create a table of the median \"SALARY\" grouped by \"ONET_NAME\", and include a count of records (as \"Job_Postings\"), you can use pandas in Python. Here's how you can do it:\n",
    "\n",
    "✅ Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae76412a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Sample: Load your DataFrame\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# df = pd.read_csv('your_data.csv')  # Or however your DataFrame is created\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Group by ONET_NAME, calculate median salary and count of job postings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mdf\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mONET_NAME\u001b[39m\u001b[33m'\u001b[39m).agg(\n\u001b[32m     11\u001b[39m     SALARY_Median=(\u001b[33m'\u001b[39m\u001b[33mSALARY\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     12\u001b[39m     Job_Postings=(\u001b[33m'\u001b[39m\u001b[33mSALARY\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m ).reset_index()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Optional: Sort by Job_Postings or SALARY_Median if needed\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# result = result.sort_values(by='Job_Postings', ascending=False)\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample: Load your DataFrame\n",
    "# df = pd.read_csv('your_data.csv')  # Or however your DataFrame is created\n",
    "\n",
    "# Group by ONET_NAME, calculate median salary and count of job postings\n",
    "result = df.groupby('ONET_NAME').agg(\n",
    "    SALARY_Median=('SALARY', 'median'),\n",
    "    Job_Postings=('SALARY', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Optional: Sort by Job_Postings or SALARY_Median if needed\n",
    "# result = result.sort_values(by='Job_Postings', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb35373",
   "metadata": {},
   "source": [
    "## Additional Prompt\n",
    "I got the error TypeError: GroupedData.agg() got an unexpected keyword argument 'SALARY_Median'\n",
    "## Additional Response\n",
    "\n",
    "Ah, the error message you're getting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f03c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "TypeError: GroupedData.agg() got an unexpected keyword argument 'SALARY_Median'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0082aa2",
   "metadata": {},
   "source": [
    "suggests you're not using pandas, but PySpark instead. In PySpark, the syntax for .agg() is different — it doesn't accept keyword arguments with new column names directly.\n",
    "\n",
    "✅ Correct PySpark Version\n",
    "\n",
    "Here’s how you can do what you need in PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by ONET_NAME and calculate median salary and count of postings\n",
    "\n",
    "# First, compute Job_Postings (count) and SALARY_Median (approximate median using percentile_approx)\n",
    "result = df.groupBy(\"ONET_NAME\").agg(\n",
    "    F.expr(\"percentile_approx(SALARY, 0.5)\").alias(\"SALARY_Median\"),\n",
    "    F.count(\"*\").alias(\"Job_Postings\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba75c1e",
   "metadata": {},
   "source": [
    "# Salary Analysis by ONET Occupation Type Plot\n",
    "\n",
    "## Prompt\n",
    "Using Plotly Create a bubble chart where dataframe = onet_salary X-axis = ONET_NAME Y-axis = Median Salary Size = Job_Postings Apply custom colors and font styles.\n",
    "\n",
    "## Response\n",
    "ChatGPT said:\n",
    "\n",
    "Here's how you can create a bubble chart using Plotly with the following settings:\n",
    "\n",
    "DataFrame: onet_salary\n",
    "\n",
    "X-axis: ONET_NAME\n",
    "\n",
    "Y-axis: Median Salary\n",
    "\n",
    "Bubble Size: Job_Postings\n",
    "\n",
    "Custom Colors & Font Styles: Applied using Plotly's update_layout\n",
    "\n",
    "✅ Prerequisites\n",
    "\n",
    "Ensure you have Plotly installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e873615",
   "metadata": {},
   "source": [
    "✅ Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Sample usage (assumes 'onet_salary' is a DataFrame with relevant columns)\n",
    "fig = px.scatter(\n",
    "    onet_salary,\n",
    "    x=\"ONET_NAME\",\n",
    "    y=\"Median Salary\",\n",
    "    size=\"Job_Postings\",\n",
    "    color=\"Median Salary\",  # You can change this to another column if desired\n",
    "    hover_name=\"ONET_NAME\",\n",
    "    size_max=60,\n",
    "    title=\"Bubble Chart of ONET Median Salaries vs Job Postings\",\n",
    ")\n",
    "\n",
    "# Customize layout: fonts, colors, background\n",
    "fig.update_layout(\n",
    "    title_font=dict(family=\"Arial Black\", size=24, color=\"darkblue\"),\n",
    "    font=dict(family=\"Verdana\", size=14, color=\"black\"),\n",
    "    plot_bgcolor=\"white\",\n",
    "    paper_bgcolor=\"#f7f7f7\",\n",
    "    xaxis=dict(title=\"ONET Job Titles\", tickangle=45),\n",
    "    yaxis=dict(title=\"Median Salary ($)\", gridcolor=\"#e5e5e5\"),\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b9197",
   "metadata": {},
   "source": [
    "# Salary by Education Level Table\n",
    "\n",
    "## Prompt\n",
    "Create a table using pyspark from dataframe df_selected where there is an EDU_GROUP column, which is a grouping of column \"EDUCATION_LEVELS_NAME\". If EDUCATION_LEVELS_NAME contains No Education Listed, GED, or Associate degree then \"Associate's or lower\". If EDUCATION_LEVELS_NAME contains Bachelor's degree then Bachelor’s. If EDUCATION_LEVELS_NAME contains Master's degree then Master's. If EDUCATION_LEVELS_NAME contains Ph.D. or professional degree then PhD. ALSO Include LOT_V6_SPECIALIZED_OCCUPATION_NAME Average_Salary and MAX_YEARS_EXPERIENCE in the table\n",
    "\n",
    "## Response\n",
    "To create a table in PySpark from df_selected with the specified logic for EDU_GROUP, and include the requested columns, follow these steps:\n",
    "\n",
    "✅ Steps Overview\n",
    "\n",
    "Define EDU_GROUP using when and col from pyspark.sql.functions\n",
    "\n",
    "Select required columns\n",
    "\n",
    "Create a temporary view or save as a table if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Create the EDU_GROUP column based on EDUCATION_LEVELS_NAME\n",
    "df_with_edu_group = df_selected.withColumn(\n",
    "    \"EDU_GROUP\",\n",
    "    when(\n",
    "        col(\"EDUCATION_LEVELS_NAME\").rlike(\"(?i)No Education Listed|GED|Associate\"), \n",
    "        \"Associate's or lower\"\n",
    "    ).when(\n",
    "        col(\"EDUCATION_LEVELS_NAME\").rlike(\"(?i)Bachelor\"),\n",
    "        \"Bachelor's\"\n",
    "    ).when(\n",
    "        col(\"EDUCATION_LEVELS_NAME\").rlike(\"(?i)Master\"),\n",
    "        \"Master's\"\n",
    "    ).when(\n",
    "        col(\"EDUCATION_LEVELS_NAME\").rlike(\"(?i)Ph\\\\.D\\\\.|professional degree\"),\n",
    "        \"PhD\"\n",
    "    ).otherwise(\"Other\")  # Optional: handle unmatched entries\n",
    ")\n",
    "\n",
    "# Select required columns\n",
    "final_df = df_with_edu_group.select(\n",
    "    \"EDU_GROUP\",\n",
    "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
    "    \"Average_Salary\",\n",
    "    \"MAX_YEARS_EXPERIENCE\"\n",
    ")\n",
    "\n",
    "# Optional: Create a temporary view or save as a table\n",
    "final_df.createOrReplaceTempView(\"education_summary_view\")\n",
    "\n",
    "# Or save as permanent Hive table (optional and requires Hive support)\n",
    "# final_df.write.mode(\"overwrite\").saveAsTable(\"education_summary\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0579a",
   "metadata": {},
   "source": [
    "# Salary by Education Level Plot\n",
    "\n",
    "## Prompt\n",
    "Plot scatter plot using plotly where colors are EDU_GROUP (Associate's or lower is yellow, Bachelor's is green, Master's is blue, and PhD is purple), dataframe = final_df, x-axis is MAX_YEARS_EXPERIENCE (with jitter), y-axis is Average_Salary. Title is Garamond size 24 and all other text is Garamond size 12. All text is black.\n",
    "\n",
    "## Response\n",
    "Here's how you can create a Plotly scatter plot from a PySpark DataFrame (final_df) with the following requirements:\n",
    "\n",
    "✅ Requirements Recap:\n",
    "\n",
    "x-axis: MAX_YEARS_EXPERIENCE with jitter\n",
    "\n",
    "y-axis: Average_Salary\n",
    "\n",
    "Color by: EDU_GROUP\n",
    "\n",
    "\"Associate's or lower\" → yellow\n",
    "\n",
    "\"Bachelor's\" → green\n",
    "\n",
    "\"Master's\" → blue\n",
    "\n",
    "\"PhD\" → purple\n",
    "\n",
    "Title: font Garamond, size 24, black\n",
    "\n",
    "All other text: Garamond, size 12, black\n",
    "\n",
    "✅ Full Code (with Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ba86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Convert PySpark DataFrame to Pandas\n",
    "pdf = final_df.toPandas()\n",
    "\n",
    "# Step 2: Add jitter to MAX_YEARS_EXPERIENCE\n",
    "np.random.seed(0)\n",
    "jitter_strength = 0.3\n",
    "pdf['JITTERED_EXPERIENCE'] = pdf['MAX_YEARS_EXPERIENCE'] + np.random.uniform(\n",
    "    -jitter_strength, jitter_strength, size=len(pdf)\n",
    ")\n",
    "\n",
    "# Step 3: Define custom color mapping\n",
    "color_map = {\n",
    "    \"Associate's or lower\": 'yellow',\n",
    "    \"Bachelor's\": 'green',\n",
    "    \"Master's\": 'blue',\n",
    "    \"PhD\": 'purple'\n",
    "}\n",
    "\n",
    "# Step 4: Create the Plotly scatter plot\n",
    "fig = px.scatter(\n",
    "    pdf,\n",
    "    x='JITTERED_EXPERIENCE',\n",
    "    y='Average_Salary',\n",
    "    color='EDU_GROUP',\n",
    "    color_discrete_map=color_map,\n",
    "    title=\"Average Salary vs. Max Years of Experience by Education Group\",\n",
    "    labels={\n",
    "        'JITTERED_EXPERIENCE': 'Max Years of Experience (jittered)',\n",
    "        'Average_Salary': 'Average Salary',\n",
    "        'EDU_GROUP': 'Education Group'\n",
    "    },\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "# Step 5: Update layout with Garamond font and sizes\n",
    "fig.update_layout(\n",
    "    title_font=dict(family='Garamond', size=24, color='black'),\n",
    "    font=dict(family='Garamond', size=12, color='black'),\n",
    "    legend_title_font=dict(family='Garamond', size=12, color='black'),\n",
    "    legend_font=dict(family='Garamond', size=12, color='black')\n",
    ")\n",
    "\n",
    "# Step 6: Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7181853",
   "metadata": {},
   "source": [
    "# Salary by Remote Work Type Histograms\n",
    "\n",
    "## Prompt\n",
    "create a plotly histogram where the x-axis is \"MAX_YEARS_EXPERIENCE\" split into groups of 1, and the y axis is \"Average_Salary\", dataframe is remote_df, and group by REMOTE_TYPE_NAME\n",
    "\n",
    "## Response\n",
    "To create a Plotly histogram where:\n",
    "\n",
    "x = MAX_YEARS_EXPERIENCE (binned by 1 year),\n",
    "\n",
    "y = Average_Salary,\n",
    "\n",
    "grouped by = REMOTE_TYPE_NAME,\n",
    "\n",
    "you’ll want to use Plotly Express with histfunc='avg' so that it computes the average salary per bin, and use nbins or manually bin the experience column.\n",
    "\n",
    "✅ Option 1: Use Plotly’s Built-in Histogram Aggregation\n",
    "\n",
    "This is the simplest approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52863713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(\n",
    "    remote_df,\n",
    "    x=\"MAX_YEARS_EXPERIENCE\",\n",
    "    y=\"Average_Salary\",\n",
    "    color=\"REMOTE_TYPE_NAME\",\n",
    "    histfunc=\"avg\",               # compute average salary per bin\n",
    "    nbins=int(remote_df['MAX_YEARS_EXPERIENCE'].max()) + 1,\n",
    "    title=\"Average Salary by Years of Experience and Remote Type\",\n",
    "    labels={\n",
    "        'MAX_YEARS_EXPERIENCE': 'Max Years of Experience',\n",
    "        'Average_Salary': 'Average Salary',\n",
    "        'REMOTE_TYPE_NAME': 'Remote Work Type'\n",
    "    },\n",
    "    barmode='group'  # group bars side by side\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Max Years of Experience\",\n",
    "    yaxis_title=\"Average Salary\",\n",
    "    bargap=0.2\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9cd9fc",
   "metadata": {},
   "source": [
    "## Additional Prompt\n",
    "I got the error TypeError: 'Column' object is not callable\n",
    "\n",
    "## Additional Response\n",
    "Thanks — that error suggests you're using PySpark DataFrame (remote_df) directly with Plotly, which doesn't work because Plotly expects a Pandas DataFrame, not a PySpark one.\n",
    "\n",
    "The error likely came from this line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "nbins=int(remote_df['MAX_YEARS_EXPERIENCE'].max()) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d197ab",
   "metadata": {},
   "source": [
    "In PySpark, remote_df['MAX_YEARS_EXPERIENCE'] returns a Column object, not a value — which leads to the TypeError: 'Column' object is not callable.\n",
    "\n",
    "✅ Fix: Convert to Pandas First\n",
    "\n",
    "You must convert your PySpark DataFrame to Pandas before plotting with Plotly:\n",
    "\n",
    "✔️ Step-by-step Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| eval: false\n",
    "\n",
    "# Step 1: Convert to Pandas\n",
    "pdf = remote_df.toPandas()\n",
    "\n",
    "# Step 2: Create plot using Plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(\n",
    "    pdf,\n",
    "    x=\"MAX_YEARS_EXPERIENCE\",\n",
    "    y=\"Average_Salary\",\n",
    "    color=\"REMOTE_TYPE_NAME\",\n",
    "    histfunc=\"avg\",\n",
    "    nbins=int(pdf['MAX_YEARS_EXPERIENCE'].max()) + 1,\n",
    "    barmode='group',\n",
    "    title=\"Average Salary by Years of Experience and Remote Type\",\n",
    "    labels={\n",
    "        'MAX_YEARS_EXPERIENCE': 'Max Years of Experience',\n",
    "        'Average_Salary': 'Average Salary',\n",
    "        'REMOTE_TYPE_NAME': 'Remote Work Type'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(dtick=1),\n",
    "    yaxis_title=\"Average Salary\",\n",
    "    bargap=0.2\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
